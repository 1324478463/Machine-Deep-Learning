# VGG

## 概要

卷积网络（ConvNets）近来在大规模图像和视频识别方面取得了巨大成功（Krizhevsky等，2012；Zeiler＆Fergus，2013；Sermanet等，2014；Simonyan＆Zisserman，2014）由于大的公开图像存储库，例如ImageNet，以及高性能计算系统的出现，例如GPU或大规模分布式集群（Dean等，2012），使这成为可能。特别是，在深度视觉识别架构的进步中，ImageNet大型视觉识别挑战（ILSVRC）（Russakovsky等，2014）发挥了重要作用，它已经成为几代大规模图像分类系统的测试台，从高维度浅层特征编码（Perronnin等，2010）（ILSVRC-2011的获胜者）到深层ConvNets（Krizhevsky等，2012）（ILSVRC-2012的获奖者）。

随着ConvNets在计算机视觉领域越来越商品化，为了达到更好的准确性，已经进行了许多尝试来<u>改进Krizhevsky等人（2012）最初的架构</u>。例如，ILSVRC-2013（Zeiler＆Fergus，2013；Sermanet等，2014）表现最佳的提交使用了**更小的感受窗口尺寸和更小的第一卷积层步长**。另一条改进措施**在整个图像和多个尺度上对网络进行密集地训练和测试**（Sermanet等，2014；Howard，2014）。

在本文中，我们解决了ConvNet架构设计的另一个重要方面——其深度。为此，我们修正了架构的其它参数，并通过添加更多的卷积层来稳定地增加网络的深度，这是可行的，**因为在所有层中使用非常小的（3×3）卷积滤波器。**

## 新意

我们的主要贡献是使用非常小的（3×3）卷积滤波器架构对网络深度的增加进行了全面评估，这表明通过将深度推到16-19加权层可以实现对现有技术配置的显著改进。

两个3×3卷积层堆叠（没有空间池化）有5×5的有效感受野；三个这样的层具有7×7的有效感受野。

那么我们获得了什么？例如通过使用三个3×3卷积层的堆叠来替换单个7×7层。

* 首先，我们结合了三个非线性修正层，而不是单一的，这使得决策函数更具判别性。
* 其次，我们减少参数的数量：假设三层3×3**卷积堆叠的输入和输出有C个通道**，堆叠卷积层的参数为$3*(3^2C^2)=27C^2$个权重；同时，单个7×7卷积层将需要$7^2C^2=49C^2$个参数，即参数多81％。

这可以看作是对7×7卷积滤波器进行正则化(减少了参数)，迫使它们通过3×3滤波器（在它们之间**注入非线性**）进行分解。

## 架构

ConvNet配置（以列显示）。随着更多的层被添加，配置的深度从左（A）增加到右（E）（添加的层以粗体显示）。卷积层参数表示为“conv⟨感受野大小⟩-通道数⟩”。为了简洁起见，不显示ReLU激活功能。

![Table 1](http://upload-images.jianshu.io/upload_images/3232548-a104f82ae41bc025.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们报告了每个配置的参数数量。尽管深度很大，我们的网络中权重数量并不大于**具有更大卷积层宽度和感受野的较浅网络**中的权重数量（144M的权重在（Sermanet等人，2014）中）。

参数数量（百万级别）:

![Table 2](http://upload-images.jianshu.io/upload_images/3232548-eae7cd7adad61842.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 训练

1. 预处理: 

   * 在训练期间，我们的ConvNet的输入是固定大小的224×224 RGB图像。

     令S是等轴归一化的训练图像的最小边，ConvNet输入从S中裁剪（我们也将S称为训练尺度）。虽然裁剪尺寸固定为224×224，但原则上S可以是不小于224的任何值：

     * 对于S=224，裁剪图像将捕获整个图像的统计数据，完全扩展训练图像的最小边；

     * 对于S»224，裁剪图像将对应于图像的一小部分，包含小对象或对象的一部分。

     我们考虑两种方法来设置训练尺度S。

     * 第一种是修正对应单尺度训练的S（注意，采样裁剪图像中的图像内容仍然可以表示多尺度图像统计）。在我们的实验中，我们评估了以两个固定尺度训练的模型. 256/384.

     * 第二种是多尺度训练，其中每个训练图像通过从一定范围[Smin，Smax]（我们使用Smin=256和Smax=512）随机采样S来单独进行归一化。由于图像中的目标可能具有不同的大小，因此在训练期间考虑到这一点是有益的。这也可以看作是**通过尺度抖动进行训练集增强**，其中单个模型被训练在一定尺度范围内识别对象。

       为了速度的原因，我们通过对具有相同配置的单尺度模型的所有层进行微调，训练了多尺度模型，并用固定的S=384进行预训练。

   * 我们**唯一的预处理是从每个像素中减去在训练集上计算的RGB均值**。

2. 优化手段

   * 使用具有动量的小批量梯度下降（基于反向传播（LeCun等人，1989））优化多项式逻辑回归目标函数来进行训练。批量大小设为256，动量为0.9。

   * 学习率初始设定为$10^{−2}$，然后当验证集准确率停止改善时，减少10倍。学习率总共降低3次，学习在37万次迭代后停止（74个epochs）。

     > 我们推测，尽管与（Krizhevsky等，2012）相比我们的网络参数更多，网络的深度更大，但网络需要更小的epoch就可以收敛，这是由于
     >
     > * 由更大的深度和更小的卷积滤波器尺寸引起的**隐式正则化**
     > * 某些层的预初始化。
     >
     > 值得注意的是，在提交论文之后，我们发现可以通过使用**Glorot＆Bengio（2010）**的随机初始化程序来初始化权重而不进行预训练。

3. 正则化
   * 训练通过权重衰减（L2惩罚乘子设定为$5*10^{−4}$）进行正则化.
   * 前两个全连接层执行丢弃正则化（丢弃率设定为0.5）

## 测试

在测试时，给出训练的ConvNet和输入图像，它按以下方式分类。首先，将其等轴地归一化到预定义的最小图像边，表示为Q（我们也将其称为测试尺度）。我们注意到，**Q不一定等于训练尺度S**（正如我们在第4节中所示，每个S使用Q的几个值会导致性能改进）。

我们还通过水平翻转图像来增强测试集, **将原始图像和翻转图像的softmax类后验进行平均**，以获得图像的最终分数。

