# 风格迁移

> 历史介绍:https://zhuanlan.zhihu.com/p/26746283

> ![img](https://pic1.zhimg.com/80/v2-526f16430324d3fbd8c07ff3d1c05c0b_hd.jpg)
>
> *图像风格迁移科技树*
>
> 在神经网络之前，图像风格迁移的程序有一个共同的思路：分析某一种风格的图像，给那一种风格建立一个数学或者统计模型，再改变要做迁移的图像让它能更好的符合建立的模型。这样做出来效果还是不错的，比如下面的三张图中所示，但一个很大的缺点：**一个程序基本只能做某一种风格或者某一个场景**。因此基于传统风格迁移研究的实际应用非常有限。
>
> ![img](https://pic2.zhimg.com/80/v2-59558f2733d67e635eae6fa6a62e0039_hd.jpg)
>
> [景色照片时间迁移](http://dl.acm.org/citation.cfm?id=2508419)
>
> 改变了这种现状的是两篇Gatys的论文，在这之前让程序模仿任意一张图片画画是没法想象的。
>
> ![img](https://pic4.zhimg.com/80/v2-77e4dc591850616514eca142dcc79daa_hd.jpg)
>
> 第一个基于神经网络的图像风格迁移算法，生成时间：5-20分钟*
>
> 因为VGG19的优秀表现，引起了很多兴趣和讨论，但是VGG19具体内部在做什么其实很难理解，因为每一个神经元内部参数只是一堆数字而已。每个神经元有几百个输入和几百个输出，一个一个去梳理清楚神经元和神经元之间的关系太难。
>
> 于是有人想出来一种办法：虽然我们不知道神经元是怎么工作的，但是如果我们知道了它的**激活条件**，会不会能对理解神经网络更有帮助呢？于是他们编了一个程序，（用的方法叫back propagation，和训练神经网络的方法一样，只是倒过来生成图片。）把每个神经元所对应的能激活它的图片找了出来，之前的那幅特征提取示意图就是这么生成的。有人在这之上又进一步，觉得，诶既然我们能找到一个神经元的激活条件，那能不能把所有关于“狗’的神经元找出来，让他们全部被激活，然后看看对于神经网络来说”狗“长什么样子的？
>
> 长得其实是这样的：
>
> ![img](https://pic3.zhimg.com/80/v2-d793ef70697509e624bc043457b67997_hd.jpg)
>
> *神经网络想象中的狗*.
>
> 这是神经网络想象中最完美的狗的样子，非常迷幻，感觉都可以自成一派搞个艺术风格出来了。而能把任何图片稍作修改让神经网络产生那就是狗的幻觉的程序被称作deep dream。
>
> 基于神经网络的图像风格迁移在2015年由Gatys et al. 在两篇论文中提出：[Gatys et al., 2015a](http://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks)和[Gatys et al., 2015b](https://arxiv.org/abs/1508.06576)。
>
> 我们先说第一篇。第一篇比起之前的纹理生成算法，创新点只有一个：它给了一种用深度学习来给纹理建模的方法。之前说到纹理生成的一个重要的假设是纹理能够通过局部统计模型来描述，而手动建模方法太麻烦。于是Gatys看了一眼隔壁的物体识别论文，发现VGG19说白了不就是一堆局部特征识别器嘛。他把事先训练好的网络拿过来一看，发现这些识别器还挺好用的。于是Gatys套了个Gramian matrix上去算了一下那些不同局部特征的相关性，把它变成了一个统计模型，于是就有了一个不用手工建模就能生成纹理的方法。
>
> ![img](https://pic1.zhimg.com/80/v2-99f6ed199359a99d9b8524d7f86ac328_hd.jpg)
>
> *基于神经网络的纹理生成算法*
>
> 从纹理到图片风格其实只差两步。第一步也是比较神奇的，是Gatys发现**纹理能够描述一个图像的风格**。严格来说纹理只是图片风格的一部分，但是不仔细研究纹理和风格之间的区别的话，乍一看给人感觉还真差不多。第二步是**如何只提取图片内容而不包括图片风格**。这两点就是他的第二篇论文做的事情：Gatys又偷了个懒，把物体识别模型再拿出来用了一遍，这次不拿Gramian算统计模型了，直接把局部特征看做近似的图片内容，这样就得到了一个把图片内容和图片风格（说白了就是纹理）分开的系统，剩下的就是把一个图片的内容和另一个图片的风格合起来。合起来的方法用的正是之前提到的让神经网络“梦到”狗的方法，也就是研究员们玩出来的Deep Dream，找到能让合适的特征提取神经元被激活的图片即可。

## 细节

> https://blog.csdn.net/qq_25737169/article/details/79192211

其中，风格迁移算法的成功，其主要基于以下两点：

> 1. 两张图像**经过预训练好的分类网络**，若提取出的<u>高维特征($high−level$)之间的欧氏距离越小</u>，则这两张图像内容越相似
> 2. 两张图像**经过预训练好的分类网络**，若提取出的<u>低维特征($low−level$)在数值上基本相等</u>，则这两张图像越相似，换句话说，两张图像相似等价于二者特征的Gram矩阵具有较小的弗罗贝尼乌斯范数。

> 設 ![A](https://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=000000&s=0) 為一個 ![m\times n](https://s0.wp.com/latex.php?latex=m%5Ctimes+n&bg=ffffff&fg=000000&s=0) 階實矩陣，![n](https://s0.wp.com/latex.php?latex=n&bg=ffffff&fg=000000&s=0) 階方陣 ![G=[g_{ij}]=A^TA](https://s0.wp.com/latex.php?latex=G%3D%5Bg_%7Bij%7D%5D%3DA%5ETA&bg=ffffff&fg=000000&s=0) 稱為 **Gramian 或 Gram 矩陣**，也有人稱之為交互乘積 (cross-product) 矩陣。考慮 ![A](https://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=000000&s=0) 的行向量表達式 ![A=\begin{bmatrix}    \mathbf{a}_1&\mathbf{a}_2&\cdots&\mathbf{a}_n    \end{bmatrix}](https://s0.wp.com/latex.php?latex=A%3D%5Cbegin%7Bbmatrix%7D++++%5Cmathbf%7Ba%7D_1%26%5Cmathbf%7Ba%7D_2%26%5Ccdots%26%5Cmathbf%7Ba%7D_n++++%5Cend%7Bbmatrix%7D&bg=ffffff&fg=000000&s=0)，![\mathbf{a}_i\in\mathbb{R}^m](https://s0.wp.com/latex.php?latex=%5Cmathbf%7Ba%7D_i%5Cin%5Cmathbb%7BR%7D%5Em&bg=ffffff&fg=000000&s=0)，則
>
> ​	![G=A^TA=\begin{bmatrix}  \mathbf{a}_1^T\\    \mathbf{a}_2^T\\    \vdots\\    \mathbf{a}_n^T    \end{bmatrix}\begin{bmatrix}    \mathbf{a}_1&\mathbf{a}_2&\cdots&\mathbf{a}_n    \end{bmatrix}=\begin{bmatrix}    \mathbf{a}_1^T\mathbf{a}_1&\mathbf{a}_1^T\mathbf{a}_2&\cdots&\mathbf{a}_1^T\mathbf{a}_n\\    \mathbf{a}_2^T\mathbf{a}_1&\mathbf{a}_2^T\mathbf{a}_2&\cdots&\mathbf{a}_2^T\mathbf{a}_n\\    ~&~&~&~\\    \mathbf{a}_n^T\mathbf{a}_1&\mathbf{a}_n^T\mathbf{a}_2&\cdots&\mathbf{a}_n^T\mathbf{a}_n    \end{bmatrix}](https://s0.wp.com/latex.php?latex=G%3DA%5ETA%3D%5Cbegin%7Bbmatrix%7D++%5Cmathbf%7Ba%7D_1%5ET%5C%5C++++%5Cmathbf%7Ba%7D_2%5ET%5C%5C++++%5Cvdots%5C%5C++++%5Cmathbf%7Ba%7D_n%5ET++++%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D++++%5Cmathbf%7Ba%7D_1%26%5Cmathbf%7Ba%7D_2%26%5Ccdots%26%5Cmathbf%7Ba%7D_n++++%5Cend%7Bbmatrix%7D%3D%5Cbegin%7Bbmatrix%7D++++%5Cmathbf%7Ba%7D_1%5ET%5Cmathbf%7Ba%7D_1%26%5Cmathbf%7Ba%7D_1%5ET%5Cmathbf%7Ba%7D_2%26%5Ccdots%26%5Cmathbf%7Ba%7D_1%5ET%5Cmathbf%7Ba%7D_n%5C%5C++++%5Cmathbf%7Ba%7D_2%5ET%5Cmathbf%7Ba%7D_1%26%5Cmathbf%7Ba%7D_2%5ET%5Cmathbf%7Ba%7D_2%26%5Ccdots%26%5Cmathbf%7Ba%7D_2%5ET%5Cmathbf%7Ba%7D_n%5C%5C++++%7E%26%7E%26%7E%26%7E%5C%5C++++%5Cmathbf%7Ba%7D_n%5ET%5Cmathbf%7Ba%7D_1%26%5Cmathbf%7Ba%7D_n%5ET%5Cmathbf%7Ba%7D_2%26%5Ccdots%26%5Cmathbf%7Ba%7D_n%5ET%5Cmathbf%7Ba%7D_n++++%5Cend%7Bbmatrix%7D&bg=ffffff&fg=000000&s=0)
>
> > https://ccjou.wordpress.com/2011/03/07/%E7%89%B9%E6%AE%8A%E7%9F%A9%E9%99%A3-14%EF%BC%9Agramian-%E7%9F%A9%E9%99%A3/(线代启示录)
>
> Frobenius 范数(弗罗贝尼乌斯范数)，简称F-范数，是一种矩阵范数，记为$||·||_F$。矩阵A的Frobenius范数定义为矩阵A各项元素的绝对值平方的总和，即![1537950655175](../../%E4%B8%8B%E8%BD%BD/Markdown/assets/1537950655175.png)

Gram矩阵实际上是矩阵的内积运算，在风格迁移算法中，其计算的是feature map之间的**偏心协方差**，在feature map 包含着图像的特征，每个数字表示特征的强度，**Gram矩阵代表着特征之间的相关性**，因此，Gram矩阵可以用来表示图像的风格，因此可以**通过Gram矩阵衡量风格的差异性**。

![1537951686974](../../%E4%B8%8B%E8%BD%BD/Markdown/assets/1537951686974.png)

![1537951727193](../../%E4%B8%8B%E8%BD%BD/Markdown/assets/1537951727193.png)

![1537951769401](../../%E4%B8%8B%E8%BD%BD/Markdown/assets/1537951769401.png)

这里使用了Gram矩阵,而非协方差矩阵,实际上协方差矩阵也可以,就是运算成本更高.

![1537951940305](../../%E4%B8%8B%E8%BD%BD/Markdown/assets/1537951940305.png)

![1537952236766](../../%E4%B8%8B%E8%BD%BD/Markdown/assets/1537952236766.png)

![1537952253735](../../%E4%B8%8B%E8%BD%BD/Markdown/assets/1537952253735.png)

![1537952485755](../../%E4%B8%8B%E8%BD%BD/Markdown/assets/1537952485755.png)





## 参考

https://zhuanlan.zhihu.com/p/24383274(深度学习实践：使用Tensorflow实现快速风格迁移)

https://zhuanlan.zhihu.com/p/36238178

https://zhuanlan.zhihu.com/p/26913182

https://mp.weixin.qq.com/s/iV-OXiKF1jgAhSmX4QUIXw(图像风格化算法最全盘点 | 内附大量扩展应用)