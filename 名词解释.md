## epoch

指所有训练数据完成一次前向和后向传递，与batch大小有关.

## Multilayer Perceptron, MLP

多层感知器, 是一种前向结构的[人工神经网络](https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)，映射一组输入向量到一组输出向量。MLP可以被看作是一个有向图，由多个的节点层所组成，每一层都全连接到下一层。除了输入节点，每个节点都是一个带有非线性激活函数的神经元（或称处理单元）。一种被称为[反向传播算法](https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95)的[监督学习](https://zh.wikipedia.org/wiki/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0)方法常被用来训练MLP。MLP是[感知器](https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8)的推广，克服了感知器不能对[线性不可分](https://zh.wikipedia.org/w/index.php?title=%E7%BA%BF%E6%80%A7%E4%B8%8D%E5%8F%AF%E5%88%86&action=edit&redlink=1)数据进行识别的弱点。

若每个神经元的激活函数都是线性函数，那么，任意层数的MLP都可被约简成一个等价的单层[感知器](https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8)。

实际上，MLP本身可以使用任何形式的激活函数，譬如阶梯函数或[逻辑乙形函数](https://zh.wikipedia.org/w/index.php?title=%E9%80%BB%E8%BE%91%E4%B9%99%E5%BD%A2%E5%87%BD%E6%95%B0&action=edit&redlink=1)（logistic sigmoid function），但为了使用反向传播算法进行有效学习，激活函数必须限制为[可微函数](https://zh.wikipedia.org/wiki/%E5%8F%AF%E5%BE%AE%E5%87%BD%E6%95%B0)。由于具有良好可微性，很多[S函数](https://zh.wikipedia.org/wiki/S%E5%87%BD%E6%95%B0)，尤其是[双曲正切函数](https://zh.wikipedia.org/wiki/%E5%8F%8C%E6%9B%B2%E6%AD%A3%E5%88%87%E5%87%BD%E6%95%B0)（Hyperbolic tangent）及[逻辑函数](https://zh.wikipedia.org/wiki/%E9%80%BB%E8%BE%91%E5%87%BD%E6%95%B0)，被采用为激活函数。

